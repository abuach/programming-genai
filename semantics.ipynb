{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f673a6a",
   "metadata": {},
   "source": [
    "# Semantics\n",
    "\n",
    "```{admonition} Learning Objectives\n",
    "After reading this chapter, you will be able to:\n",
    "* **Understand** the distributional hypothesis and how it enables learning meaning from raw text without explicit definitions.\n",
    "* **Understand** how semantic similarity can be measured geometrically using vector operations in high-dimensional space.  \n",
    "```\n",
    "\n",
    "## Words Become Coordinates\n",
    "\n",
    "Have you ever wondered how when you're texting on your phone, the autocomplete and next-word prediction seems to *know* what you're going to say after you type the first few words? Or how a search engine like Google can find documents that don't contain your *exact* query terms, but somehow capture what you *meant*? The answer lies in one of the most elegant ideas in modern AI: **embeddings**.\n",
    "\n",
    "An embedding is a way of representing discrete objects—like words, sentences, or even entire programs—as points in a high-dimensional space. It is a learned mapping from discrete objects (words, sentences, code snippets) to continuous vectors in ℝⁿ, where n is typically between 100 and 1000+ dimensions. The key insight is that we can train these mappings so that semantically similar items end up close together in embedding space. \n",
    "\n",
    "Mathematically, an embedding is a function:\n",
    "\n",
    "```\n",
    "embed: Object → ℝⁿ\n",
    "```\n",
    "\n",
    "For example, a word embedding might map:\n",
    "- \"cat\" → [0.2, -0.5, 0.8, ..., 0.1]\n",
    "- \"kitten\" → [0.18, -0.48, 0.79, ..., 0.12]\n",
    "- \"dog\" → [0.15, -0.45, 0.75, ..., 0.08]\n",
    "\n",
    "Notice that \"cat\" and \"kitten\" have similar vectors (they're nearby in space), while \"cat\" and \"algorithm\" would be far apart.\n",
    "\n",
    "This seemingly simple transformation unlocks something profound: the ability to measure how *similar* two pieces of text or code are, not by counting matching characters, but by understanding their *meaning*.\n",
    "\n",
    "In this chapter, we'll explore how embeddings transform the fuzzy, ambiguous world of natural language into the precise realm of geometry. We'll see how the same principles that work for text can be applied to source code, opening up new possibilities for program analysis and software engineering. Along the way, we'll build intuition through hands-on examples and discover why distance in embedding space often corresponds to semantic similarity.\n",
    "\n",
    "## The Problem with Symbolic Representations\n",
    "\n",
    "Let's start with a puzzle. How similar are these two sentences?\n",
    "\n",
    "1. \"The cat sat on the mat.\"\n",
    "2. \"A feline rested on the rug.\"\n",
    "\n",
    "To a human, these sentences clearly mean almost the same thing. But to a computer using traditional string matching, they share almost no words in common! This is the fundamental challenge of symbolic representations: objects that are semantically similar may have no obvious surface-level similarity.\n",
    "\n",
    "Before embeddings, the standard approach was to represent text as a \"bag of words\"—literally just counting which words appear:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd189547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word overlap similarity: 0.22\n"
     ]
    }
   ],
   "source": [
    "def word_overlap(sent1, sent2):\n",
    "    \"\"\"Calculate similarity by counting shared words.\"\"\"\n",
    "    words1 = set(sent1.lower().split())\n",
    "    words2 = set(sent2.lower().split())\n",
    "    overlap = len(words1 & words2)\n",
    "    total = len(words1 | words2)\n",
    "    return overlap / total if total > 0 else 0\n",
    "\n",
    "s1 = \"The cat sat on the mat\"\n",
    "s2 = \"A feline rested on the rug\"\n",
    "print(f\"Word overlap similarity: {word_overlap(s1, s2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a000cc",
   "metadata": {},
   "source": [
    "This approach loses all word order and, more importantly, treats every word as completely unrelated to every other word. \"Cat\" and \"feline\" are no more similar than \"cat\" and \"economics.\"\n",
    "\n",
    "This toy example reveals a deep truth: we need a representation that captures *meaning*, not just surface form.\n",
    "\n",
    "## The Distributional Hypothesis\n",
    "\n",
    "The breakthrough came from a deceptively simple idea, articulated by linguist John Firth in 1957: **\"You shall know a word by the company it keeps.\"**\n",
    "\n",
    "This is called the **distributional hypothesis**: words that appear in similar contexts tend to have similar meanings. Think about it:\n",
    "\n",
    "- \"The ___ chased the mouse\" \n",
    "- \"The ___ climbed the tree\"\n",
    "- \"The ___ meowed loudly\"\n",
    "\n",
    "What word fits in all these blanks? Probably \"cat.\" And if you saw a new word, say \"feline,\" appearing in the same contexts, you'd reasonably conclude it means something similar.\n",
    "\n",
    "This insight is profound because it gives us a way to learn meaning from raw text, without anyone having to explicitly define what words mean.\n",
    "\n",
    "## Word Embeddings: Words as Vectors\n",
    "\n",
    "A **word embedding** represents each word as a vector—a point in high-dimensional space. Typically, these vectors have 50, 100, 300, or even more dimensions. Words with similar meanings end up close together in this space.\n",
    "\n",
    "Let's build intuition with a toy example in 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c103a9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Toy embeddings for animal words (2D for visualization)\n",
    "embeddings = {\n",
    "    'cat': np.array([0.8, 0.9]),\n",
    "    'dog': np.array([0.9, 0.8]),\n",
    "    'kitten': np.array([0.75, 0.95]),\n",
    "    'puppy': np.array([0.95, 0.75]),\n",
    "    'car': np.array([0.1, 0.1]),\n",
    "    'vehicle': np.array([0.15, 0.05])\n",
    "}\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 8))\n",
    "for word, vec in embeddings.items():\n",
    "    plt.scatter(vec[0], vec[1], s=100)\n",
    "    plt.annotate(word, vec, fontsize=12)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('Toy Word Embeddings in 2D Space')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97e6d99",
   "metadata": {},
   "source": [
    "In this space, `cat` and `kitten` are close together, as are `dog` and `puppy`. But `car` is far from the animals. The geometry encodes semantic relationships!\n",
    "\n",
    "## 7.4: Measuring Similarity: Cosine Distance\n",
    "\n",
    "How do we quantify similarity between vectors? The most common metric is **cosine similarity**, which measures the angle between vectors:\n",
    "\n",
    "$$\\text{cosine similarity}(\\vec{a}, \\vec{b}) = \\frac{\\vec{a} \\cdot \\vec{b}}{|\\vec{a}| \\cdot |\\vec{b}|}$$\n",
    "\n",
    "This gives us a value between -1 (opposite) and 1 (identical), with 0 meaning perpendicular (unrelated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c18d7803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat-dog similarity: 0.993\n",
      "cat-kitten similarity: 0.998\n",
      "cat-car similarity: 0.998\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# Compare similarities\n",
    "cat_dog = cosine_similarity(embeddings['cat'], embeddings['dog'])\n",
    "cat_kitten = cosine_similarity(embeddings['cat'], embeddings['kitten'])\n",
    "cat_car = cosine_similarity(embeddings['cat'], embeddings['car'])\n",
    "\n",
    "print(f\"cat-dog similarity: {cat_dog:.3f}\")\n",
    "print(f\"cat-kitten similarity: {cat_kitten:.3f}\")\n",
    "print(f\"cat-car similarity: {cat_car:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c88d4",
   "metadata": {},
   "source": [
    "Why cosine instead of Euclidean distance? Because we care about direction (meaning) more than magnitude. Two vectors pointing in the same direction are similar, even if one is longer.\n",
    "\n",
    "## 7.5: Word2Vec: Learning Embeddings from Context\n",
    "\n",
    "The Word2Vec algorithm, introduced by Mikolov et al. in 2013, was a watershed moment. It learns embeddings by training a neural network to predict words from their context (or vice versa).\n",
    "\n",
    "### The Skip-Gram Model\n",
    "\n",
    "The **skip-gram** variant works like this: given a center word, predict the surrounding context words. For example, in \"the quick brown fox jumps,\" if \"brown\" is the center word, we try to predict \"quick\" and \"fox.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a1976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pairs: [('the', 'quick'), ('the', 'brown'), ('quick', 'the'), ('quick', 'brown'), ('quick', 'fox'), ('brown', 'the'), ('brown', 'quick'), ('brown', 'fox'), ('brown', 'jumps'), ('fox', 'quick')]\n"
     ]
    }
   ],
   "source": [
    "# Simplified skip-gram training concept\n",
    "def generate_training_pairs(text, window_size=2):\n",
    "    \"\"\"Generate (center_word, context_word) pairs.\"\"\"\n",
    "    words = text.split()\n",
    "    pairs = []\n",
    "    \n",
    "    for i, center in enumerate(words):\n",
    "        # Get context words within window\n",
    "        start = max(0, i - window_size)\n",
    "        end = min(len(words), i + window_size + 1)\n",
    "        \n",
    "        for j in range(start, end):\n",
    "            if i != j:  # Don't pair word with itself\n",
    "                pairs.append((center, words[j]))\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "text = \"the quick brown fox jumps over the lazy dog\"\n",
    "pairs = generate_training_pairs(text, window_size=2)\n",
    "print(f\"Training pairs: {pairs[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61791941",
   "metadata": {},
   "source": [
    "The network learns by adjusting embeddings so that words appearing in similar contexts have similar vectors. The magic is that these vectors capture semantic relationships we never explicitly programmed!\n",
    "\n",
    "## 7.6: Vector Arithmetic and Analogies\n",
    "\n",
    "One of the most fascinating properties of word embeddings is that they support arithmetic. The famous example:\n",
    "\n",
    "$$\\text{king} - \\text{man} + \\text{woman} \\approx \\text{queen}$$\n",
    "\n",
    "Let's see this with real embeddings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "415b7278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing: king - man + woman = ?\n",
      "\n",
      "Candidate similarities:\n",
      "  queen: 0.7886\n",
      "  prince: 0.4847\n",
      "  princess: 0.6553\n",
      "  duke: 0.4452\n",
      "  duchess: 0.5961\n",
      "  lord: 0.4515\n",
      "  lady: 0.5580\n",
      "  emperor: 0.4748\n",
      "  empress: 0.6314\n",
      "\n",
      " Best answer: queen (similarity: 0.7886)\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import numpy as np\n",
    "\n",
    "def get_embedding(word):\n",
    "    \"\"\"Get embedding vector for a word using Ollama.\"\"\"\n",
    "    response = ollama.embeddings(model='nomic-embed-text', prompt=word)\n",
    "    return np.array(response['embedding'])\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Calculate cosine similarity between vectors.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def analogy(a, b, c, candidate_words):\n",
    "    \"\"\"Solve analogy: a is to b as c is to ?\n",
    "    \n",
    "    Args:\n",
    "        a, b, c: The analogy words (e.g., 'king', 'man', 'woman')\n",
    "        candidate_words: List of potential answer words to search\n",
    "    \"\"\"\n",
    "    print(f\"Computing: {a} - {b} + {c} = ?\")\n",
    "    \n",
    "    # Get embeddings\n",
    "    emb_a = get_embedding(a)\n",
    "    emb_b = get_embedding(b)\n",
    "    emb_c = get_embedding(c)\n",
    "    \n",
    "    # Perform vector arithmetic: king - man + woman\n",
    "    result_vec = emb_a - emb_b + emb_c\n",
    "    \n",
    "    # Find closest word among candidates\n",
    "    best_word = None\n",
    "    best_sim = -1\n",
    "    \n",
    "    print(\"\\nCandidate similarities:\")\n",
    "    for word in candidate_words:\n",
    "        if word.lower() in [a.lower(), b.lower(), c.lower()]:\n",
    "            continue\n",
    "            \n",
    "        word_emb = get_embedding(word)\n",
    "        sim = cosine_similarity(result_vec, word_emb)\n",
    "        print(f\"  {word}: {sim:.4f}\")\n",
    "        \n",
    "        if sim > best_sim:\n",
    "            best_sim = sim\n",
    "            best_word = word\n",
    "    \n",
    "    return best_word, best_sim\n",
    "\n",
    "# Test the classic example\n",
    "candidates = ['queen', 'prince', 'princess', 'duke', 'duchess', \n",
    "              'lord', 'lady', 'emperor', 'empress']\n",
    "\n",
    "answer, similarity = analogy('king', 'man', 'woman', candidates)\n",
    "print(f\"\\n Best answer: {answer} (similarity: {similarity:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6326d4",
   "metadata": {},
   "source": [
    "This works because the embedding space captures relationships. The \"royalty\" dimension and the \"gender\" dimension exist implicitly in the geometry, learned entirely from data.\n",
    "\n",
    "## 7.7: Sentence Embeddings: Beyond Individual Words\n",
    "\n",
    "Words are useful, but we often need to understand entire sentences or documents. How do we embed a sentence?\n",
    "\n",
    "### Simple Averaging (Bag of Words Embeddings)\n",
    "\n",
    "The simplest approach: average the word vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16d5c26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing sentence embeddings by averaging word vectors...\n",
      "\n",
      "Getting embeddings for: ['the', 'cat', 'sat', 'on', 'the', 'mat']\n",
      "Getting embeddings for: ['a', 'feline', 'rested', 'on', 'the', 'rug']\n",
      "Getting embeddings for: ['python', 'is', 'a', 'programming', 'language']\n",
      "\n",
      " Results:\n",
      "'The cat sat on the mat' vs 'A feline rested on the rug': 0.937\n",
      "'The cat sat on the mat' vs 'Python is a programming language': 0.809\n",
      "'A feline rested on the rug' vs 'Python is a programming language': 0.843\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Calculate cosine similarity between vectors.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_word_embedding(word):\n",
    "    \"\"\"Get embedding for a single word using Ollama.\"\"\"\n",
    "    response = ollama.embeddings(model='nomic-embed-text', prompt=word)\n",
    "    return np.array(response['embedding'])\n",
    "\n",
    "def sentence_embedding_average(sentence):\n",
    "    \"\"\"Create sentence embedding by averaging word vectors.\"\"\"\n",
    "    words = sentence.lower().split()\n",
    "    vectors = []\n",
    "    \n",
    "    print(f\"Getting embeddings for: {words}\")\n",
    "    for word in words:\n",
    "        vec = get_word_embedding(word)\n",
    "        vectors.append(vec)\n",
    "    \n",
    "    if not vectors:\n",
    "        return np.zeros(768)  # nomic-embed-text uses 768 dimensions\n",
    "    \n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# Example usage\n",
    "sent1 = \"The cat sat on the mat\"\n",
    "sent2 = \"A feline rested on the rug\"\n",
    "sent3 = \"Python is a programming language\"\n",
    "\n",
    "print(\"Computing sentence embeddings by averaging word vectors...\\n\")\n",
    "\n",
    "emb1 = sentence_embedding_average(sent1)\n",
    "emb2 = sentence_embedding_average(sent2)\n",
    "emb3 = sentence_embedding_average(sent3)\n",
    "\n",
    "# Calculate similarities\n",
    "sim_1_2 = cosine_similarity(emb1, emb2)\n",
    "sim_1_3 = cosine_similarity(emb1, emb3)\n",
    "sim_2_3 = cosine_similarity(emb2, emb3)\n",
    "\n",
    "print(f\"\\n Results:\")\n",
    "print(f\"'{sent1}' vs '{sent2}': {sim_1_2:.3f}\")\n",
    "print(f\"'{sent1}' vs '{sent3}': {sim_1_3:.3f}\")\n",
    "print(f\"'{sent2}' vs '{sent3}': {sim_2_3:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6770da57",
   "metadata": {},
   "source": [
    "This is better than bag-of-words counting, but it still loses word order and grammar.\n",
    "\n",
    "### Modern Approaches: Transformers\n",
    "\n",
    "Today's state-of-the-art sentence embeddings come from **transformer models** like BERT and sentence-transformers. These models use attention mechanisms to understand how words relate within a sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8f2e901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Now using PROPER sentence embeddings (context-aware):\n",
      "\n",
      " Results with proper embeddings:\n",
      "'The cat sat on the mat' vs 'A feline rested on the rug': 0.698\n",
      "'The cat sat on the mat' vs 'Python is a programming language': 0.402\n",
      "\n",
      " Discrimination Analysis (Similar - Different):\n",
      "Higher scores = better at distinguishing similar from different\n",
      "\n",
      "Averaged words approach:\n",
      "  Similar: 0.937 | Different: 0.809\n",
      "  Discrimination: 0.128\n",
      "\n",
      "Proper embeddings approach:\n",
      "  Similar: 0.698 | Different: 0.402\n",
      "  Discrimination: 0.296\n",
      "\n",
      " Winner: Proper embeddings\n",
      "   Improvement: 0.169\n",
      "   (132.4% better)\n"
     ]
    }
   ],
   "source": [
    "def get_sentence_embedding(sentence):\n",
    "    \"\"\"Get embedding for entire sentence using Ollama.\"\"\"\n",
    "    response = ollama.embeddings(model='nomic-embed-text', prompt=sentence)\n",
    "    return np.array(response['embedding'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Now using PROPER sentence embeddings (context-aware):\\n\")\n",
    "\n",
    "# Get proper sentence embeddings\n",
    "sent_emb1 = get_sentence_embedding(sent1)\n",
    "sent_emb2 = get_sentence_embedding(sent2)\n",
    "sent_emb3 = get_sentence_embedding(sent3)\n",
    "\n",
    "# Calculate similarities\n",
    "proper_sim_1_2 = cosine_similarity(sent_emb1, sent_emb2)\n",
    "proper_sim_1_3 = cosine_similarity(sent_emb1, sent_emb3)\n",
    "\n",
    "print(f\" Results with proper embeddings:\")\n",
    "print(f\"'{sent1}' vs '{sent2}': {proper_sim_1_2:.3f}\")\n",
    "print(f\"'{sent1}' vs '{sent3}': {proper_sim_1_3:.3f}\")\n",
    "\n",
    "# Calculate discrimination: how well does each approach separate similar from different?\n",
    "avg_discrimination = sim_1_2 - sim_1_3  # similar - different\n",
    "proper_discrimination = proper_sim_1_2 - proper_sim_1_3\n",
    "\n",
    "print(\"\\n Discrimination Analysis (Similar - Different):\")\n",
    "print(f\"Higher scores = better at distinguishing similar from different\\n\")\n",
    "print(f\"Averaged words approach:\")\n",
    "print(f\"  Similar: {sim_1_2:.3f} | Different: {sim_1_3:.3f}\")\n",
    "print(f\"  Discrimination: {avg_discrimination:.3f}\")\n",
    "\n",
    "print(f\"\\nProper embeddings approach:\")\n",
    "print(f\"  Similar: {proper_sim_1_2:.3f} | Different: {proper_sim_1_3:.3f}\")\n",
    "print(f\"  Discrimination: {proper_discrimination:.3f}\")\n",
    "\n",
    "print(f\"\\n Winner: {'Proper embeddings' if proper_discrimination > avg_discrimination else 'Averaged words'}\")\n",
    "print(f\"   Improvement: {abs(proper_discrimination - avg_discrimination):.3f}\")\n",
    "print(f\"   ({abs((proper_discrimination - avg_discrimination) / avg_discrimination * 100):.1f}% better)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc6ccb5",
   "metadata": {},
   "source": [
    "This comparison shows that proper embeddings provide ***much better discrimination***—they give higher scores to truly similar sentences and lower scores to different ones, making them more useful for real applications like semantic search!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d143cc74",
   "metadata": {},
   "source": [
    "## 7.8: Applications of Text Embeddings\n",
    "\n",
    "Embeddings power countless modern applications:\n",
    "\n",
    "### Semantic Search\n",
    "\n",
    "Traditional search matches keywords. Semantic search finds meaning:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32700750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Searching for: 'artificial intelligence and algorithms'\n",
      "\n",
      "📊 Results:\n",
      "0.769 ███████████████      Machine learning is a subset of AI\n",
      "0.559 ███████████          Python is great for data science\n",
      "0.556 ███████████          Neural networks learn from data\n",
      "0.409 ████████             The weather today is sunny\n",
      "\n",
      "======================================================================\n",
      "\n",
      "🔍 Searching for: 'programming languages for statistics'\n",
      "\n",
      "📊 Results:\n",
      "0.669 █████████████        Python is great for data science\n",
      "0.505 ██████████           Machine learning is a subset of AI\n",
      "0.466 █████████            Neural networks learn from data\n",
      "0.439 ████████             The weather today is sunny\n",
      "\n",
      "======================================================================\n",
      "\n",
      "🔍 Searching for: 'how's the climate outside?'\n",
      "\n",
      "📊 Results:\n",
      "0.629 ████████████         The weather today is sunny\n",
      "0.408 ████████             Python is great for data science\n",
      "0.382 ███████              Machine learning is a subset of AI\n",
      "0.329 ██████               Neural networks learn from data\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import numpy as np\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"Get embedding using Ollama.\"\"\"\n",
    "    response = ollama.embeddings(model='nomic-embed-text', prompt=text)\n",
    "    return np.array(response['embedding'])\n",
    "\n",
    "def semantic_search(query, documents):\n",
    "    \"\"\"Find most relevant documents using embeddings.\"\"\"\n",
    "    print(f\"🔍 Searching for: '{query}'\\n\")\n",
    "    \n",
    "    # Get query embedding\n",
    "    query_emb = get_embedding(query)\n",
    "    \n",
    "    # Get document embeddings\n",
    "    doc_embs = [get_embedding(doc) for doc in documents]\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = [cosine_similarity(query_emb, doc_emb) for doc_emb in doc_embs]\n",
    "    \n",
    "    # Return documents sorted by relevance\n",
    "    ranked = sorted(zip(documents, similarities), \n",
    "                   key=lambda x: x[1], reverse=True)\n",
    "    return ranked\n",
    "\n",
    "# Example documents\n",
    "docs = [\n",
    "    \"Machine learning is a subset of AI\",\n",
    "    \"Python is great for data science\",\n",
    "    \"The weather today is sunny\",\n",
    "    \"Neural networks learn from data\"\n",
    "]\n",
    "\n",
    "# Search with different queries\n",
    "queries = [\n",
    "    \"artificial intelligence and algorithms\",\n",
    "    \"programming languages for statistics\",\n",
    "    \"how's the climate outside?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    results = semantic_search(query, docs)\n",
    "    \n",
    "    print(\"📊 Results:\")\n",
    "    for doc, score in results:\n",
    "        # Add visual indicator\n",
    "        bar = \"█\" * int(score * 20)\n",
    "        print(f\"{score:.3f} {bar:20s} {doc}\")\n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c5ff1",
   "metadata": {},
   "source": [
    "This finds relevant documents even without exact keyword matches!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1df89b0",
   "metadata": {},
   "source": [
    "### Document Clustering\n",
    "\n",
    "Another useful application of sentence embeddings is grouping similar documents together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c62e654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Embedding documents...\n",
      " Created embeddings: (10, 768)\n",
      "\n",
      " Document clusters (k=3): [0 2 2 0 1 2 0 1 2 0]\n",
      "\n",
      "======================================================================\n",
      "\n",
      " Cluster 0:\n",
      "   • Machine learning is a subset of AI\n",
      "   • Neural networks learn from data\n",
      "   • Deep learning uses multi-layer neural networks\n",
      "   • AI systems can recognize patterns in data\n",
      "\n",
      " Cluster 1:\n",
      "   • JavaScript is used for web development\n",
      "   • Ruby on Rails is a web framework\n",
      "\n",
      " Cluster 2:\n",
      "   • Python is great for data science\n",
      "   • The weather today is sunny\n",
      "   • It's raining cats and dogs outside\n",
      "   • The temperature dropped to freezing\n",
      "\n",
      "======================================================================\n",
      "\n",
      " Cluster Analysis:\n",
      "\n",
      "Cluster 0 (4 docs):\n",
      "  Average intra-cluster similarity: 0.649\n",
      "  Cohesion: High\n",
      "\n",
      "Cluster 1 (2 docs):\n",
      "  Average intra-cluster similarity: 0.620\n",
      "  Cohesion: High\n",
      "\n",
      "Cluster 2 (4 docs):\n",
      "  Average intra-cluster similarity: 0.491\n",
      "  Cohesion: Medium\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"Get embedding using Ollama.\"\"\"\n",
    "    response = ollama.embeddings(model='nomic-embed-text', prompt=text)\n",
    "    return np.array(response['embedding'])\n",
    "\n",
    "# Collection of documents\n",
    "documents = [\n",
    "    \"Machine learning is a subset of AI\",\n",
    "    \"Python is great for data science\",\n",
    "    \"The weather today is sunny\",\n",
    "    \"Neural networks learn from data\",\n",
    "    \"JavaScript is used for web development\",\n",
    "    \"It's raining cats and dogs outside\",\n",
    "    \"Deep learning uses multi-layer neural networks\",\n",
    "    \"Ruby on Rails is a web framework\",\n",
    "    \"The temperature dropped to freezing\",\n",
    "    \"AI systems can recognize patterns in data\"\n",
    "]\n",
    "\n",
    "print(\" Embedding documents...\")\n",
    "# Embed all documents\n",
    "docs_emb = np.array([get_embedding(doc) for doc in documents])\n",
    "print(f\" Created embeddings: {docs_emb.shape}\\n\")\n",
    "\n",
    "# Cluster into k groups\n",
    "n_clusters = 3\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(docs_emb)\n",
    "\n",
    "print(f\" Document clusters (k={n_clusters}): {clusters}\\n\")\n",
    "\n",
    "# Display documents by cluster\n",
    "print(\"=\"*70)\n",
    "for cluster_id in range(n_clusters):\n",
    "    print(f\"\\n Cluster {cluster_id}:\")\n",
    "    cluster_docs = [doc for doc, c in zip(documents, clusters) if c == cluster_id]\n",
    "    for doc in cluster_docs:\n",
    "        print(f\"   • {doc}\")\n",
    "\n",
    "# Calculate cluster cohesion\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\n Cluster Analysis:\")\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Calculate cosine similarity between vectors.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "for cluster_id in range(n_clusters):\n",
    "    cluster_indices = [i for i, c in enumerate(clusters) if c == cluster_id]\n",
    "    cluster_vectors = docs_emb[cluster_indices]\n",
    "    \n",
    "    # Calculate average intra-cluster similarity\n",
    "    if len(cluster_vectors) > 1:\n",
    "        similarities = []\n",
    "        for i in range(len(cluster_vectors)):\n",
    "            for j in range(i+1, len(cluster_vectors)):\n",
    "                sim = cosine_similarity(cluster_vectors[i], cluster_vectors[j])\n",
    "                similarities.append(sim)\n",
    "        \n",
    "        avg_similarity = np.mean(similarities)\n",
    "        print(f\"\\nCluster {cluster_id} ({len(cluster_indices)} docs):\")\n",
    "        print(f\"  Average intra-cluster similarity: {avg_similarity:.3f}\")\n",
    "        print(f\"  Cohesion: {'High' if avg_similarity > 0.6 else 'Medium' if avg_similarity > 0.4 else 'Low'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02be0cb3",
   "metadata": {},
   "source": [
    "## Conclusion: From Words to Sentences—The Leap to Context\n",
    "\n",
    "We've journeyed from the simple idea of averaging word vectors to the sophisticated reality of modern sentence embeddings.\n",
    "\n",
    "**FOCUS**: A sentence is more than the sum of its words. \"The dog bit the man\" and \"The man bit the dog\" use identical words but convey completely different meanings. Order matters. Context matters. Grammar matters.\n",
    "\n",
    "Our experiments helped the progression of our understanding of how LLMs grasp text semantics:\n",
    "\n",
    "**We learned**: \n",
    "\n",
    "1. **Use the model's native sentence embeddings** when available. Don't average word vectors unless you're experimenting or have severe constraints. Models like `nomic-embed-text` are trained end-to-end to understand sentences holistically.\n",
    "\n",
    "2. **Measure what matters**. We introduced the discrimination score (within-category similarity minus across-category similarity) because it captures whether embeddings actually help with your task. High cosine similarity means nothing if you can't distinguish what needs distinguishing.\n",
    "\n",
    "3. **Context is everything**. The same word \"bank\" gets different embeddings depending on whether we're discussing finance or geography. Modern contextual embeddings (which we'll explore more in later chapters) solve this by making every word's representation depend on its surrounding context.\n",
    "\n",
    "**Looking ahead**: Sentence embeddings are the foundation for virtually every modern NLP application—semantic search, question answering, document clustering, recommendation systems, and even retrieval-augmented generation (RAG) systems that power today's AI assistants. The geometry we've studied here—cosine similarity, vector spaces, dimensionality—appears everywhere in modern AI.\n",
    "\n",
    "But we're just scratching the surface. The same principles that let us embed sentences also let us embed **code**, images, audio, and even entire documents or knowledge bases. In the next sections, we'll see how these ideas extend to code embeddings, enabling AI systems that can search entire codebases for relevant functions and assist with code reviews on GitHub, for starters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "programming-genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
