{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e44713",
   "metadata": {},
   "source": [
    "# Agentic\n",
    "\n",
    "```{admonition} Learning Objectives\n",
    "\n",
    "After reading this chapter, you will be able to:\n",
    "\n",
    "* **Explain** the difference between conversational AI and agentic AI systems\n",
    "* **Describe**  how tool calling bridges the gap between language generation and real-world actions\n",
    "* **Identify**  scenarios where tool calling is necessary versus when direct text generation suffices\n",
    "```\n",
    "\n",
    "## From Conversation to Action\n",
    "\n",
    "Imagine you're working on a group project, and instead of just talking about what needs to be done, your teammate can actually *do* thingsâ€”check the calendar, send emails, look up information, even write code. That's the leap we're making in this chapter: from language models that can only *talk* about actions to AI agents that can *take* actions.\n",
    "\n",
    "In the early days of large language models, we were thrilled when they could answer questions and generate text. But there was always a gap: they lived in a world of words, disconnected from the tools and systems we use every day. Tool calling bridges that gap, transforming language models from eloquent conversationalists into capable assistants.\n",
    "\n",
    "## The Core Idea: Structured Function Calling\n",
    "\n",
    "At its heart, tool calling is about giving language models a structured way to say \"I need to use this specific function with these specific parameters.\" Instead of just generating text that *describes* what should happen, the model generates structured data that your code can execute.\n",
    "\n",
    "Let's see this in action with Ollama and the Qwen3 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b73b2aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolCall(function=Function(name='get_weather', arguments={'location': 'Paris', 'unit': 'celsius'}))]\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "# Define a simple tool: get the current weather\n",
    "tools = [{\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "        'name': 'get_weather',\n",
    "        'description': 'Get the current weather for a location',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'location': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'City name, e.g. San Francisco'\n",
    "                },\n",
    "                'unit': {\n",
    "                    'type': 'string',\n",
    "                    'enum': ['celsius', 'fahrenheit'],\n",
    "                    'description': 'Temperature unit'\n",
    "                }\n",
    "            },\n",
    "            'required': ['location']\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='qwen3',\n",
    "    messages=[{'role': 'user', 'content': 'What is the weather in Paris?'}],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "print(response['message']['tool_calls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eeddc1",
   "metadata": {},
   "source": [
    "What's happening here? We've given the model a *schema*â€”a formal description of what the `get_weather` function expects. When the model sees \"What is the weather in Paris?\", it recognizes it needs to call a tool and outputs structured JSON rather than freeform text.\n",
    "\n",
    "## Anatomy of a Tool Definition\n",
    "\n",
    "Tool definitions follow a specific structure that tells the model everything it needs to know:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb25d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tool = {\n",
    "    'type': 'function',  # Currently, 'function' is the only type\n",
    "    'function': {\n",
    "        'name': 'get_weather',  # Unique identifier\n",
    "        'description': 'Get weather for a location',  # Helps model decide when to use it\n",
    "        'parameters': {  # JSON Schema for the parameters\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'location': {'type': 'string', 'description': 'City name'},\n",
    "                'unit': {'type': 'string', 'enum': ['celsius', 'fahrenheit']}\n",
    "            },\n",
    "            'required': ['location']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b11e640",
   "metadata": {},
   "source": [
    "The `description` field is crucialâ€”it's how the model decides *when* to use the tool. Good descriptions are clear, specific, and include examples when helpful.\n",
    "\n",
    "## Building Your First Agent Loop\n",
    "\n",
    "An agent isn't just one tool callâ€”it's a *conversation* between the model and your tools. Here's the basic loop:\n",
    "\n",
    "1. User sends a message\n",
    "2. Model decides if it needs a tool\n",
    "3. If yes, model generates tool call(s)\n",
    "4. You execute the tool(s)\n",
    "5. You send results back to model\n",
    "6. Model responds to user (or calls more tools!)\n",
    "\n",
    "Let's implement this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71247179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location, unit='celsius'):\n",
    "    \"\"\"Simulated weather API\"\"\"\n",
    "    return {\n",
    "        'location': location,\n",
    "        'temperature': 22 if unit == 'celsius' else 72,\n",
    "        'conditions': 'sunny',\n",
    "        'unit': unit\n",
    "    }\n",
    "\n",
    "def run_agent(user_message):\n",
    "    messages = [{'role': 'user', 'content': user_message}]\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model='qwen2.5:latest',\n",
    "        messages=messages,\n",
    "        tools=[weather_tool]\n",
    "    )\n",
    "    \n",
    "    # Check if model wants to call a tool\n",
    "    if response['message'].get('tool_calls'):\n",
    "        # Add model's response to messages\n",
    "        messages.append(response['message'])\n",
    "        \n",
    "        # Execute each tool call\n",
    "        for tool in response['message']['tool_calls']:\n",
    "            if tool['function']['name'] == 'get_weather':\n",
    "                args = tool['function']['arguments']\n",
    "                result = get_weather(**args)\n",
    "                \n",
    "                # Add tool result to messages\n",
    "                messages.append({\n",
    "                    'role': 'tool',\n",
    "                    'content': json.dumps(result),\n",
    "                })\n",
    "        \n",
    "        # Get final response with tool results\n",
    "        final_response = ollama.chat(\n",
    "            model='qwen2.5:latest',\n",
    "            messages=messages\n",
    "        )\n",
    "        return final_response['message']['content']\n",
    "    \n",
    "    return response['message']['content']\n",
    "\n",
    "# Try it!\n",
    "print(run_agent(\"What's the weather like in Tokyo?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e8bee",
   "metadata": {},
   "source": [
    "Notice the message flow: user message â†’ model response with tool call â†’ tool result â†’ final model response. This is the fundamental pattern of agentic AI.\n",
    "\n",
    "## Multiple Tools: Expanding Capabilities\n",
    "\n",
    "Real agents have access to multiple tools. Let's create a more interesting agent:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db3d7f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'calculate',\n",
    "            'description': 'Perform mathematical calculations',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'expression': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'Math expression like \"2 + 2\" or \"sqrt(16)\"'\n",
    "                    }\n",
    "                },\n",
    "                'required': ['expression']\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'search_database',\n",
    "            'description': 'Search a product database',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'query': {'type': 'string', 'description': 'Search query'},\n",
    "                    'max_results': {'type': 'integer', 'description': 'Max results'}\n",
    "                },\n",
    "                'required': ['query']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def calculate(expression):\n",
    "    \"\"\"Safe calculator\"\"\"\n",
    "    try:\n",
    "        return {'result': eval(expression, {'__builtins__': {}}, \n",
    "                              {'sqrt': __import__('math').sqrt})}\n",
    "    except:\n",
    "        return {'error': 'Invalid expression'}\n",
    "\n",
    "def search_database(query, max_results=5):\n",
    "    \"\"\"Simulated database\"\"\"\n",
    "    products = {\n",
    "        'laptop': {'name': 'UltraBook Pro', 'price': 1299},\n",
    "        'phone': {'name': 'SmartPhone X', 'price': 899}\n",
    "    }\n",
    "    return [v for k, v in products.items() if query.lower() in k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacbc22b",
   "metadata": {},
   "source": [
    "The model will now automatically choose which tool to use based on the user's request!\n",
    "\n",
    "## Parallel Tool Calls: Efficiency Matters\n",
    "\n",
    "Sometimes an agent needs to call multiple tools at once. Modern models support parallel tool calls:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50493f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling get_weather with args:\n",
      "{'location': 'London'}\n",
      "Calling get_weather with args:\n",
      "{'location': 'Paris'}\n"
     ]
    }
   ],
   "source": [
    "# User asks: \"What's the weather in London and Paris?\"\n",
    "response = ollama.chat(\n",
    "    model='qwen3:latest',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'What is the weather in London and Paris?'\n",
    "    }],\n",
    "    tools=[weather_tool]\n",
    ")\n",
    "\n",
    "# Model might return multiple tool calls at once!\n",
    "for tool_call in response['message'].get('tool_calls', []):\n",
    "    print(f\"Calling {tool_call['function']['name']} with args:\")\n",
    "    print(tool_call['function']['arguments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445fe684",
   "metadata": {},
   "source": [
    "This is more efficient than sequential calls and shows how agents can be surprisingly sophisticated in their planning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6660442c",
   "metadata": {},
   "source": [
    "## Chain of Thought with Tools\n",
    "\n",
    "Sometimes agents need to \"think\" before acting. Reasoning models like DeepSeek-R1 make their thought process explicit through a special thinking field. This gives us unprecedented insight into why an agent chooses to use certain tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89431c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "USER: If I have a circle with radius 5, what's its area? Also, what's that area divided by the golden ratio?\n",
      "============================================================\n",
      "\n",
      "AGENT'S INTERNAL REASONING (Step 1):\n",
      "------------------------------------------------------------\n",
      "Okay, the user is asking about the area of a circle with radius 5 and then wants that area divided by the golden ratio. Let me break this down.\n",
      "\n",
      "First, the area of a circle is Ï€ multiplied by the radius squared. The radius here is 5, so the formula would be Ï€ * 5Â². That simplifies to Ï€ * 25. So the area is 25Ï€. I can calculate that numerically using the get_constant function for Ï€. Alternatively, maybe the user wants the exact value in terms of Ï€, but since they mentioned dividing by the golden ...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸ”§ TOOL CALLS:\n",
      "  â†’ get_constant(constant='pi')\n",
      "    âœ“ Result: {'constant': 'pi', 'value': 3.141592653589793}\n",
      "  â†’ get_constant(constant='golden_ratio')\n",
      "    âœ“ Result: {'constant': 'golden_ratio', 'value': 1.618033988749895}\n",
      "\n",
      "AGENT'S INTERNAL REASONING (Step 2):\n",
      "------------------------------------------------------------\n",
      "Okay, let's see. The user asked for two things: the area of a circle with radius 5 and then that area divided by the golden ratio.\n",
      "\n",
      "First, I need to calculate the area of the circle. The formula is Ï€ multiplied by radius squared. The radius is 5, so 5 squared is 25. Then multiply by Ï€, which we got from the get_constant function as approximately 3.141592653589793. So 25 * Ï€ equals about 78.53981633974483.\n",
      "\n",
      "Next, the user wants that area divided by the golden ratio. The golden ratio value from th...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸ”§ TOOL CALLS:\n",
      "  â†’ calculate(expression='25 * 3.141592653589793')\n",
      "    âœ“ Result: {'result': 78.53981633974483, 'expression': '25 * 3.141592653589793'}\n",
      "  â†’ calculate(expression='78.53981633974483 / 1.618033988749895')\n",
      "    âœ“ Result: {'result': 48.54027596813666, 'expression': '78.53981633974483 / 1.618033988749895'}\n",
      "\n",
      "AGENT'S INTERNAL REASONING (Step 3):\n",
      "------------------------------------------------------------\n",
      "Okay, let me wrap this up. The user asked for two things: the area of a circle with radius 5 and then that area divided by the golden ratio.\n",
      "\n",
      "First, I calculated the area using the formula Ï€rÂ². With r = 5, that's 25Ï€. Using the value of Ï€ from the get_constant function (3.141592653589793), the area came out to approximately 78.5398.\n",
      "\n",
      "Next, I divided that area by the golden ratio, which was retrieved as 1.618033988749895. The result of that division is roughly 48.5403.\n",
      "\n",
      "So, the final answers are:...\n",
      "------------------------------------------------------------\n",
      "\n",
      "AGENT RESPONSE:\n",
      "The area of a circle with radius 5 is calculated as:  \n",
      "$$\n",
      "\\text{Area} = \\pi \\times r^2 = 3.141592653589793 \\times 25 \\approx 78.54\n",
      "$$  \n",
      "\n",
      "Dividing this area by the golden ratio ($\\phi \\approx 1.618033988749895$):  \n",
      "$$\n",
      "\\frac{78.5398}{1.618034} \\approx 48.54\n",
      "$$  \n",
      "\n",
      "**Final Answers:**  \n",
      "- **Area of the circle:** $ \\boxed{78.54} $  \n",
      "- **Area divided by the golden ratio:** $ \\boxed{48.54} $\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "# Define tools for our thoughtful agent\n",
    "math_tools = [\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'calculate',\n",
    "            'description': 'Evaluate a mathematical expression',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'expression': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'Math expression like \"2 + 2\" or \"sqrt(16)\"'\n",
    "                    }\n",
    "                },\n",
    "                'required': ['expression']\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'get_constant',\n",
    "            'description': 'Get the value of mathematical constants',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'constant': {\n",
    "                        'type': 'string',\n",
    "                        'enum': ['pi', 'e', 'golden_ratio'],\n",
    "                        'description': 'The mathematical constant to retrieve'\n",
    "                    }\n",
    "                },\n",
    "                'required': ['constant']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def calculate(expression):\n",
    "    \"\"\"Safe mathematical calculator\"\"\"\n",
    "    import math\n",
    "    safe_dict = {\n",
    "        'sqrt': math.sqrt,\n",
    "        'sin': math.sin,\n",
    "        'cos': math.cos,\n",
    "        'pi': math.pi,\n",
    "        'e': math.e\n",
    "    }\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}}, safe_dict)\n",
    "        return {'result': result, 'expression': expression}\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "def get_constant(constant):\n",
    "    \"\"\"Retrieve mathematical constants\"\"\"\n",
    "    import math\n",
    "    constants = {\n",
    "        'pi': math.pi,\n",
    "        'e': math.e,\n",
    "        'golden_ratio': (1 + math.sqrt(5)) / 2\n",
    "    }\n",
    "    return {'constant': constant, 'value': constants[constant]}\n",
    "\n",
    "def thoughtful_agent(user_message):\n",
    "    \"\"\"Agent that shows its reasoning process\"\"\"\n",
    "    messages = [{'role': 'user', 'content': user_message}]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"USER: {user_message}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    max_iterations = 5  # Prevent infinite loops\n",
    "    iteration = 0\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        \n",
    "        # Get response from DeepSeek-R1\n",
    "        response = ollama.chat(\n",
    "            model='qwen3:latest',\n",
    "            messages=messages,\n",
    "            tools=math_tools\n",
    "        )\n",
    "        \n",
    "        # DeepSeek-R1 exposes internal reasoning in 'thinking' field\n",
    "        if response['message'].get('thinking'):\n",
    "            print(f\"AGENT'S INTERNAL REASONING (Step {iteration}):\")\n",
    "            print(\"-\" * 60)\n",
    "            # Truncate long thinking for readability\n",
    "            thinking = response['message']['thinking']\n",
    "            if len(thinking) > 500:\n",
    "                print(thinking[:500] + \"...\")\n",
    "            else:\n",
    "                print(thinking)\n",
    "            print(\"-\" * 60)\n",
    "            print()\n",
    "        \n",
    "        # Check if model wants to use tools\n",
    "        if not response['message'].get('tool_calls'):\n",
    "            print(\"AGENT RESPONSE:\")\n",
    "            print(response['message']['content'])\n",
    "            return response['message']['content']\n",
    "        \n",
    "        # Add assistant's message to conversation\n",
    "        messages.append(response['message'])\n",
    "        \n",
    "        # Execute each tool call\n",
    "        print(\"ðŸ”§ TOOL CALLS:\")\n",
    "        for tool_call in response['message']['tool_calls']:\n",
    "            func_name = tool_call['function']['name']\n",
    "            args = tool_call['function']['arguments']\n",
    "            \n",
    "            print(f\"  â†’ {func_name}({', '.join(f'{k}={repr(v)}' for k, v in args.items())})\")\n",
    "            \n",
    "            # Execute the function\n",
    "            if func_name == 'calculate':\n",
    "                result = calculate(args['expression'])\n",
    "            elif func_name == 'get_constant':\n",
    "                result = get_constant(args['constant'])\n",
    "            else:\n",
    "                result = {'error': f'Unknown function: {func_name}'}\n",
    "            \n",
    "            print(f\"    âœ“ Result: {result}\")\n",
    "            \n",
    "            # Add tool result to messages\n",
    "            messages.append({\n",
    "                'role': 'tool',\n",
    "                'content': json.dumps(result)\n",
    "            })\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    return \"Max iterations reached\"\n",
    "\n",
    "# Try it with a complex query!\n",
    "result = thoughtful_agent(\n",
    "    \"If I have a circle with radius 5, what's its area? \"\n",
    "    \"Also, what's that area divided by the golden ratio?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e5a11",
   "metadata": {},
   "source": [
    "The `thinking` field is like having x-ray vision into the model's decision-making process! This is invaluable for:\n",
    "\n",
    "- **Debugging**: Understanding why the agent chose specific tools\n",
    "- **Trust**: Seeing the logical steps builds confidence in results\n",
    "- **Education**: Learning how to break down complex problems\n",
    "- **Error diagnosis**: Spotting flawed reasoning before tool execution\n",
    "\n",
    "Qwen3 and DeepSeek-R1 and similar reasoning models make this explicit, but the principle applies broadly: transparent agent reasoning leads to more reliable and debuggable systems.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "programming-genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
